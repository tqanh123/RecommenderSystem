{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c0ed50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\App\\anaconda\\envs\\gnn\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from scipy.sparse import issparse\n",
    "import json\n",
    "import inspect\n",
    "import random \n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "from typing import Optional, Dict, List, Tuple\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# ============================================= function split data =============================================\n",
    "class TestSplitter(object):\n",
    "    def __init__(self, args):\n",
    "        self.test_size = args['test_size']\n",
    "        self.uid = 'user_id'\n",
    "        self.tid = 'item_id'\n",
    "\n",
    "    def split(self, df):\n",
    "        train_index, test_index = split_test(df, self.test_size, self.uid)\n",
    "\n",
    "        return train_index, test_index\n",
    "\n",
    "\n",
    "class ValidationSplitter(object):\n",
    "    def __init__(self, args):\n",
    "        # self.fold_num = args.fold_num\n",
    "        self.val_size = args['val_size']\n",
    "        self.uid = 'user_id'\n",
    "        self.tid = 'item_id'\n",
    "\n",
    "    def split(self, df):\n",
    "        train_val_index_zip = split_validation(df, self.val_size, self.uid)\n",
    "\n",
    "        return train_val_index_zip\n",
    "\n",
    "\n",
    "def split_test(df, test_size=0.1, uid='user_id'):\n",
    "\n",
    "    test_ids = df.groupby(uid).apply(\n",
    "        lambda x: x.sample(frac=test_size).index\n",
    "    )\n",
    "    test_ids = test_ids.explode().dropna().values.astype(int)\n",
    "    # test_ids = np.array([int(x) for x in test_ids if not pd.isna(x)])\n",
    "    test_ids = np.array(list(test_ids))\n",
    "    train_ids = np.setdiff1d(df.index.values, test_ids)\n",
    "\n",
    "    return train_ids, test_ids\n",
    "\n",
    "\n",
    "def split_validation(train_set, val_size=.1, uid='user_id'):\n",
    "\n",
    "    train_set = train_set.reset_index(drop=True)\n",
    "\n",
    "    # train_set_list, val_set_list = [], []\n",
    "    # for _ in range(fold_num):\n",
    "    val_ids = train_set.groupby(uid).apply(\n",
    "        lambda x: x.sample(frac=val_size).index\n",
    "    )\n",
    "    val_ids = val_ids.explode().dropna().values.astype(int)\n",
    "    # val_ids = np.array([int(x) for x in val_ids if not pd.isna(x)])\n",
    "    # val_ids = np.array(list(val_ids))\n",
    "    train_ids = np.setdiff1d(train_set.index.values, val_ids)\n",
    "\n",
    "    # train_set     _list.append(train_ids)\n",
    "    # val_set_list.append(val_ids)\n",
    "\n",
    "    return train_ids, val_ids \n",
    "\n",
    "# ============================================= function metrics =============================================\n",
    "\n",
    "class Metric(object):\n",
    "    def __init__(self, config) -> None:\n",
    "        self.metrics = config['metrics']\n",
    "        self.item_num = config['item_num']\n",
    "        self.item_pop = config['item_pop'] if 'coverage' in self.metrics else None\n",
    "        self.i_categories = config['i_categories'] if 'diversity' in self.metrics else None\n",
    "\n",
    "    def run(self, test_ur, pred_ur, test_u):\n",
    "        res = []\n",
    "        for mc in self.metrics:\n",
    "            if mc == 'ndcg':\n",
    "                kpi = NDCG(test_ur, pred_ur, test_u)\n",
    "            elif mc == 'recall':\n",
    "                kpi = Recall(test_ur, pred_ur, test_u)\n",
    "            elif mc == 'precision':\n",
    "                kpi = Precision(test_ur, pred_ur, test_u)\n",
    "            else:\n",
    "                raise ValueError(f'Invalid metric name {mc}')\n",
    "\n",
    "            res.append(kpi)\n",
    "\n",
    "        return res\n",
    "\n",
    "def Precision(test_ur, pred_ur, test_u):\n",
    "    res = []\n",
    "    for idx in range(len(test_u)):\n",
    "        u = test_u[idx]\n",
    "        gt = test_ur[u]\n",
    "        pred = pred_ur[idx]\n",
    "        pre = np.in1d(pred, list(gt)).sum() / len(pred)\n",
    "\n",
    "        res.append(pre)\n",
    "\n",
    "    return np.mean(res)\n",
    "\n",
    "\n",
    "def Recall(test_ur, pred_ur, test_u):\n",
    "    res = []\n",
    "    for idx in range(len(test_u)):\n",
    "        u = test_u[idx]\n",
    "        gt = test_ur[u]\n",
    "        pred = pred_ur[idx]\n",
    "        rec = np.in1d(pred, list(gt)).sum() / len(gt)\n",
    "\n",
    "        res.append(rec)\n",
    "\n",
    "    return np.mean(res)\n",
    "\n",
    "def getDCG(scores):\n",
    "    return np.sum(\n",
    "        np.divide(np.power(2, scores) - 1, np.log2(np.arange(scores.shape[0], dtype=np.float32) + 1)+1),\n",
    "        # np.divide(scores, np.log2(np.arange(scores.shape[0], dtype=np.float32) + 2)+1),\n",
    "        dtype=np.float32)\n",
    "\n",
    "def getNDCG(rank_list, pos_items):\n",
    "    relevance = np.ones_like(pos_items)\n",
    "    it2rel = {it: r for it, r in zip(pos_items, relevance)}\n",
    "    rank_scores = np.asarray([it2rel.get(it, 0.0) for it in rank_list], dtype=np.float32)\n",
    "    idcg = getDCG(relevance)\n",
    "\n",
    "    dcg = getDCG(rank_scores)\n",
    "\n",
    "    if dcg == 0.0:\n",
    "        return 0.0\n",
    "\n",
    "    ndcg = dcg / idcg\n",
    "    return ndcg\n",
    "\n",
    "def NDCG(test_ur, pred_ur, test_u):\n",
    "    res = []\n",
    "    for idx in range(len(test_u)):\n",
    "        u = test_u[idx]\n",
    "        gt = test_ur[u]\n",
    "        pred = pred_ur[idx]\n",
    "        nd = getNDCG(pred, gt)\n",
    "        res.append(nd)\n",
    "    return np.mean(res)\n",
    "\n",
    "\n",
    "def AUC(test_ur, pred_ur, test_u):\n",
    "    res = []\n",
    "\n",
    "    for idx in range(len(test_u)):\n",
    "        u = test_u[idx]\n",
    "        gt = test_ur[u]\n",
    "        pred = pred_ur[idx]\n",
    "\n",
    "        r = np.in1d(pred, list(gt))\n",
    "        pos_num = r.sum()\n",
    "        neg_num = len(pred) - pos_num\n",
    "\n",
    "        # Handle edge cases: if no positive or no negative items, AUC is undefined\n",
    "        if pos_num == 0 or neg_num == 0:\n",
    "            continue  # Skip this user instead of adding NaN\n",
    "\n",
    "        pos_rank_num = 0\n",
    "        for j in range(len(r) - 1):\n",
    "            if r[j]:\n",
    "                pos_rank_num += np.sum(~r[j + 1:])\n",
    "\n",
    "        auc = pos_rank_num / (pos_num * neg_num)\n",
    "        res.append(auc)\n",
    "\n",
    "    return np.mean(res) if len(res) > 0 else 0.0\n",
    "\n",
    "def AUC_true_neg(test_ur, pred_scores, true_neg_dict, test_u):\n",
    "    aucs = []\n",
    "    for idx, u in enumerate(test_u):\n",
    "        pos = set(test_ur[u])\n",
    "        neg = true_neg_dict.get(u, set())\n",
    "        if len(pos) == 0 or len(neg) == 0:\n",
    "            continue\n",
    "\n",
    "        scores = pred_scores[idx]\n",
    "        pos_scores = [scores[i] for i in pos if i < len(scores)]\n",
    "        neg_scores = [scores[i] for i in neg if i < len(scores)]\n",
    "\n",
    "        cnt = 0\n",
    "        for ps in pos_scores:\n",
    "            cnt += sum(ps > ns for ns in neg_scores)\n",
    "\n",
    "        aucs.append(cnt / (len(pos_scores) * len(neg_scores)))\n",
    "    return np.mean(aucs) if aucs else 0.0\n",
    "\n",
    "# ============================================= function get data =============================================\n",
    "\n",
    "def get_ur(df):\n",
    "    print(\"Method of getting user-rating pairs\")\n",
    "    ur = df.groupby('user_id').item_id.apply(list).to_dict()\n",
    "    # print(ur)\n",
    "    return ur\n",
    "\n",
    "class BasicDataset(data_utils.Dataset):\n",
    "    def __init__(self, samples):\n",
    "  \n",
    "        super(BasicDataset, self).__init__()\n",
    "        self.data = samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index][0], self.data[index][1], self.data[index][2]\n",
    "\n",
    "class Cf_valDataset(data_utils.Dataset):\n",
    "    def __init__(self, data):\n",
    "        super(Cf_valDataset, self).__init__()\n",
    "        self.user = data\n",
    "        # self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.user)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        user = self.user[index]\n",
    "        return torch.tensor(user)#, torch.tensor(self.data[user])\n",
    "\n",
    "def get_train_loader(dataset, args):\n",
    "    dataloader = data_utils.DataLoader(dataset, batch_size=args['train_batch_size'], shuffle=True, pin_memory=True)\n",
    "    return dataloader\n",
    "\n",
    "def get_val_loader(dataset, args):\n",
    "    dataloader = data_utils.DataLoader(dataset, batch_size=args['val_batch_size'], shuffle=False, pin_memory=True)\n",
    "    return dataloader\n",
    "\n",
    "def get_test_loader(dataset, args):\n",
    "    dataloader = data_utils.DataLoader(dataset, batch_size=args['test_batch_size'], shuffle=False, pin_memory=True)\n",
    "    return dataloader\n",
    "\n",
    "def get_inter_matrix(df, args):\n",
    "    '''\n",
    "    get the whole sparse interaction matrix\n",
    "    '''\n",
    "    print(\"get the whole sparse interaction matrix\")\n",
    "    user_num, item_num = args['user_num'], args['item_num']\n",
    "\n",
    "    src, tar = df['user_id'].values, df['item_id'].values\n",
    "    data = df['click'].values\n",
    "\n",
    "    mat = sp.coo_matrix((data, (src, tar)), shape=(user_num, item_num))\n",
    "\n",
    "    return mat\n",
    "\n",
    "def build_relation_matrices_from_df(df: pd.DataFrame, relations: List[str], user_num: int, item_num: int) -> Dict[str, sp.coo_matrix]:\n",
    "    \"\"\"\n",
    "    df: should have columns ['user_id', 'item_id', <relations...>] with binary flags 0/1\n",
    "    relations: e.g. ['click','like','share','follow','exposed']\n",
    "    Returns dict: relation -> scipy.sparse.coo_matrix (user_num x item_num)\n",
    "    \"\"\"\n",
    "    rel_mats = {}\n",
    "    for r in relations:\n",
    "        sub = df[df[r] == 1]\n",
    "        if sub.shape[0] == 0:\n",
    "            rel_mats[r] = sp.coo_matrix((user_num, item_num))\n",
    "            continue\n",
    "        rows = sub['user_id'].values.astype(np.int32)\n",
    "        cols = sub['item_id'].values.astype(np.int32)\n",
    "        data = np.ones(len(rows), dtype=np.float32)\n",
    "        mat = sp.coo_matrix((data, (rows, cols)), shape=(user_num, item_num))\n",
    "        rel_mats[r] = mat\n",
    "    return rel_mats\n",
    "\n",
    "# ============================================= function neg sampler =============================================\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "class HybridNegativeSampler:\n",
    "    \"\"\"\n",
    "    Multi-method negative sampler for implicit CF / BPR triples.\n",
    "\n",
    "    Supported methods:\n",
    "      - 'uniform'  : sample unobserved items uniformly\n",
    "      - 'high-pop' : sample unobserved items by popularity (freq^(3/4))\n",
    "      - 'low-pop'  : sample unobserved items by inverse popularity\n",
    "      - 'true_neg' : sample from provided true negative pool per user\n",
    "      - 'hybrid'   : mix (true_neg + uniform) with ratio = sample_ratio\n",
    "\n",
    "    Usage:\n",
    "      sampler = HybridNegativeSampler(cf_args)\n",
    "      triples = sampler.sampling(df_train_edges, train_ur, true_neg_df=final_neg_pool)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, args: dict):\n",
    "        self.user_num = args['user_num']\n",
    "        self.item_num = args['item_num']\n",
    "        self.num_ng = args.get('num_ng', 4)\n",
    "\n",
    "        self.method = args.get('sampler_method', 'uniform')\n",
    "        self.sample_ratio = float(args.get('sample_ratio', 0.5))  # used by hybrid\n",
    "        self.seed = int(args.get('seed', 42))\n",
    "\n",
    "        assert self.method in ['uniform', 'high-pop', 'low-pop', 'true_neg', 'hybrid'], \\\n",
    "            f\"Invalid sampler_method: {self.method}\"\n",
    "\n",
    "        np.random.seed(self.seed)\n",
    "\n",
    "        # will be built if needed\n",
    "        self.pop_prob = None  # size = item_num\n",
    "\n",
    "    # ---------- popularity distribution ----------\n",
    "    def _build_pop_prob(self, train_edges_df):\n",
    "        \"\"\"\n",
    "        train_edges_df: DataFrame with columns ['user_id','item_id'] (encoded)\n",
    "        \"\"\"\n",
    "        cnt = Counter(train_edges_df['item_id'].values.tolist())\n",
    "        freq = np.zeros(self.item_num, dtype=np.float64)\n",
    "        for i, c in cnt.items():\n",
    "            if 0 <= i < self.item_num:\n",
    "                freq[i] = c\n",
    "\n",
    "        # smoothing like word2vec negative sampling: p(i) ~ f(i)^(3/4)\n",
    "        prob = freq / (freq.sum() + 1e-12)\n",
    "        prob = np.power(prob, 0.75)\n",
    "\n",
    "        if self.method == 'high-pop':\n",
    "            prob = prob / (prob.sum() + 1e-12)\n",
    "        elif self.method == 'low-pop':\n",
    "            # inverse popularity: items with low freq get higher probability\n",
    "            inv = 1.0 - (prob / (prob.max() + 1e-12))\n",
    "            inv = np.clip(inv, 0.0, None)\n",
    "            prob = inv / (inv.sum() + 1e-12)\n",
    "        else:\n",
    "            prob = prob / (prob.sum() + 1e-12)\n",
    "\n",
    "        self.pop_prob = prob.astype(np.float64)\n",
    "\n",
    "    # ---------- true negative dict ----------\n",
    "    @staticmethod\n",
    "    def _build_true_neg_dict(true_neg_df):\n",
    "        \"\"\"\n",
    "        true_neg_df: DataFrame ['user_id','item_id'] encoded, TRAIN-ONLY (no leakage)\n",
    "        \"\"\"\n",
    "        d = {}\n",
    "        if true_neg_df is None or len(true_neg_df) == 0:\n",
    "            return d\n",
    "        for u, i in zip(true_neg_df['user_id'].values, true_neg_df['item_id'].values):\n",
    "            d.setdefault(int(u), set()).add(int(i))\n",
    "        return d\n",
    "\n",
    "    # ---------- single draw helpers ----------\n",
    "    def _sample_uniform_one(self, u_seen, chosen):\n",
    "        j = np.random.randint(self.item_num)\n",
    "        while (j in u_seen) or (j in chosen):\n",
    "            j = np.random.randint(self.item_num)\n",
    "        return j\n",
    "\n",
    "    def _sample_pop_one(self, u_seen, chosen):\n",
    "        # assumes self.pop_prob built\n",
    "        j = int(np.random.choice(self.item_num, p=self.pop_prob))\n",
    "        tries = 0\n",
    "        while (j in u_seen) or (j in chosen):\n",
    "            j = int(np.random.choice(self.item_num, p=self.pop_prob))\n",
    "            tries += 1\n",
    "            if tries > 50:\n",
    "                # fallback to uniform to avoid dead-loop for dense users\n",
    "                return self._sample_uniform_one(u_seen, chosen)\n",
    "        return j\n",
    "\n",
    "    def _sample_true_neg_one(self, u, u_seen, chosen, true_neg_dict):\n",
    "        pool = list(true_neg_dict.get(u, []))\n",
    "        if len(pool) == 0:\n",
    "            return None\n",
    "        j = int(np.random.choice(pool))\n",
    "        tries = 0\n",
    "        while (j in u_seen) or (j in chosen):\n",
    "            j = int(np.random.choice(pool))\n",
    "            tries += 1\n",
    "            if tries > 50:\n",
    "                return None\n",
    "        return j\n",
    "\n",
    "    # ---------- main API ----------\n",
    "    def sampling(self, train_edges_df, train_ur, true_neg_df=None):\n",
    "        \"\"\"\n",
    "        Returns: np.ndarray of shape [num_triples, 3] with columns [u, pos, neg]\n",
    "        Inputs:\n",
    "          - train_edges_df: df containing positive edges used to build popularity dist (encoded)\n",
    "          - train_ur: dict user -> list(pos_items) (encoded)\n",
    "          - true_neg_df: df containing (u,i) true negatives, TRAIN-ONLY (encoded)\n",
    "        \"\"\"\n",
    "        if self.num_ng <= 0:\n",
    "            raise ValueError(\"num_ng must be > 0 for BPR\")\n",
    "\n",
    "        # Build pop dist only if needed\n",
    "        if self.method in ['high-pop', 'low-pop']:\n",
    "            self._build_pop_prob(train_edges_df)\n",
    "\n",
    "        true_neg_dict = self._build_true_neg_dict(true_neg_df) if self.method in ['true_neg', 'hybrid'] else {}\n",
    "\n",
    "        triples = []\n",
    "        for u in range(self.user_num):\n",
    "            pos_list = train_ur.get(u, [])\n",
    "            if len(pos_list) == 0:\n",
    "                continue\n",
    "            u_seen = set(pos_list)\n",
    "\n",
    "            for pos in pos_list:\n",
    "                chosen = set()\n",
    "\n",
    "                # --- HYBRID: mix true_neg + uniform (or you can change to pop if you want) ---\n",
    "                if self.method == 'hybrid':\n",
    "                    k_true = int(round(self.num_ng * self.sample_ratio))\n",
    "                    k_true = max(0, min(self.num_ng, k_true))\n",
    "                    k_other = self.num_ng - k_true\n",
    "\n",
    "                    # true neg part\n",
    "                    for _ in range(k_true):\n",
    "                        j = self._sample_true_neg_one(u, u_seen, chosen, true_neg_dict)\n",
    "                        if j is None:\n",
    "                            break\n",
    "                        chosen.add(j)\n",
    "\n",
    "                    # uniform part (fallback)\n",
    "                    while len(chosen) < self.num_ng:\n",
    "                        chosen.add(self._sample_uniform_one(u_seen, chosen))\n",
    "\n",
    "                elif self.method == 'true_neg':\n",
    "                    # only true negatives, fallback to uniform if not enough\n",
    "                    while len(chosen) < self.num_ng:\n",
    "                        j = self._sample_true_neg_one(u, u_seen, chosen, true_neg_dict)\n",
    "                        if j is None:\n",
    "                            # fallback uniform to guarantee enough negs\n",
    "                            j = self._sample_uniform_one(u_seen, chosen)\n",
    "                        chosen.add(j)\n",
    "\n",
    "                elif self.method == 'uniform':\n",
    "                    while len(chosen) < self.num_ng:\n",
    "                        chosen.add(self._sample_uniform_one(u_seen, chosen))\n",
    "\n",
    "                elif self.method in ['high-pop', 'low-pop']:\n",
    "                    while len(chosen) < self.num_ng:\n",
    "                        chosen.add(self._sample_pop_one(u_seen, chosen))\n",
    "\n",
    "                else:\n",
    "                    raise ValueError(f\"Unknown method: {self.method}\")\n",
    "\n",
    "                for neg in chosen:\n",
    "                    triples.append([u, int(pos), int(neg)])\n",
    "\n",
    "        return np.asarray(triples, dtype=np.int32)\n",
    "\n",
    "# ============================================= Model =============================================\n",
    "\n",
    "\n",
    "class LightGCN(nn.Module):\n",
    "    \"\"\"A self-contained LightGCN implementation.\n",
    "\n",
    "    Features:\n",
    "    - Builds normalized adjacency from a scipy COO interaction matrix (user-item bipartite)\n",
    "    - Layer-wise propagation (no non-linearities / no feature transform)\n",
    "    - Mean aggregation over (L+1) layers (including the 0-th embedding)\n",
    "    - Supports BPR, hinge (HL), TOP1 (TL), and point-wise (BCEWithLogits, MSE) losses via configure_loss\n",
    "    - Ranking utilities: rank(), full_rank()\n",
    "    \"\"\"\n",
    "    def __init__(self, args):\n",
    "        super().__init__()\n",
    "        self.num_users = args['user_num']\n",
    "        self.num_items = args['item_num']\n",
    "        self.embedding_dim = args.get('embedding_dim', 64)\n",
    "        self.num_layers = args.get('num_layers', 3)\n",
    "        self.interaction_matrix = args.get('interaction_matrix', None)\n",
    "        self.device = torch.device(args.get('device', 'cpu'))\n",
    "        self.reg_1 = args.get('reg_1', 0.0)\n",
    "        self.reg_2 = args.get('reg_2', 0.0)\n",
    "        self.lr = args.get('lr', 0.001)\n",
    "        self.topk = args.get('k', 20)\n",
    "        self.val_ur = args.get('val_ur', None)\n",
    "        self.val_u = args.get('val_u', None)\n",
    "        self.early_stop = args.get('early_stop', True)\n",
    "        self.save_path = args.get('save_path', './')\n",
    "        self.true_neg = args.get('true_neg', False)\n",
    "        self.true_neg_dict = args.get('true_neg_dict', {})\n",
    "        self.load = args.get('load', False)\n",
    "\n",
    "\n",
    "        # storage variables for rank evaluation acceleration\n",
    "        self.restore_user_e = None\n",
    "        self.restore_item_e = None\n",
    "\n",
    "        # Embeddings\n",
    "        self.embed_user = nn.Embedding(self.num_users, self.embedding_dim)\n",
    "        self.embed_item = nn.Embedding(self.num_items, self.embedding_dim)\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "        if self.interaction_matrix is None:\n",
    "            raise ValueError(\"interaction_matrix (scipy sparse) is required\")\n",
    "        if not sp.issparse(self.interaction_matrix):\n",
    "            raise TypeError(\"interaction_matrix must be a scipy sparse matrix\")\n",
    "\n",
    "        self.register_buffer('norm_adj_matrix', self._build_norm_adj(self.interaction_matrix).coalesce())\n",
    "\n",
    "    #  Initialization \n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Embedding):\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "\n",
    "    #  Adjacency \n",
    "    def _build_norm_adj(self, inter_M: sp.coo_matrix) -> torch.sparse.FloatTensor:\n",
    "        \"\"\"Build symmetric normalized adjacency A_hat for user-item bipartite graph.\"\"\"\n",
    "        inter_M = inter_M.tocoo()\n",
    "        A = sp.dok_matrix((self.num_users + self.num_items, self.num_users + self.num_items), dtype=np.float32)\n",
    "        # user->item (offset items by num_users)\n",
    "        data_dict = dict(zip(zip(inter_M.row, inter_M.col + self.num_users), [1]*inter_M.nnz))\n",
    "        # item->user\n",
    "        data_dict.update(dict(zip(zip(inter_M.col + self.num_users, inter_M.row), [1]*inter_M.nnz)))\n",
    "        A._update(data_dict)\n",
    "\n",
    "        sum_arr = (A > 0).sum(axis=1)\n",
    "        deg = np.array(sum_arr.flatten())[0] + 1e-7\n",
    "        deg_inv_sqrt = np.power(deg, -0.5)\n",
    "        D = sp.diags(deg_inv_sqrt)\n",
    "        L = D * A * D  # symmetric norm\n",
    "        L = sp.coo_matrix(L)\n",
    "        indices = torch.LongTensor(np.vstack([L.row, L.col]))\n",
    "        values = torch.FloatTensor(L.data)\n",
    "        return torch.sparse.FloatTensor(indices, values, torch.Size(L.shape))\n",
    "\n",
    "    #  Forward Propagation \n",
    "    def forward(self) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        all_embeddings = torch.cat([self.embed_user.weight, self.embed_item.weight], dim=0)\n",
    "        embeddings_list = [all_embeddings]\n",
    "        for _ in range(self.num_layers):\n",
    "            all_embeddings = torch.sparse.mm(self.norm_adj_matrix, all_embeddings)\n",
    "            embeddings_list.append(all_embeddings)\n",
    "        # Mean over layers\n",
    "        final = torch.mean(torch.stack(embeddings_list, dim=1), dim=1)\n",
    "        user_final, item_final = torch.split(final, [self.num_users, self.num_items])\n",
    "        return user_final, item_final\n",
    "\n",
    "    def _bpr_loss(self, pos_scores, neg_scores):\n",
    "        return -torch.mean(F.logsigmoid(pos_scores - neg_scores))\n",
    "\n",
    "    def calc_loss(self, batch):\n",
    "        # ensure model is on correct device\n",
    "        self.to(self.device)\n",
    "        # clear stored embeddings before computing\n",
    "        if self.restore_user_e is not None or self.restore_item_e is not None:\n",
    "            self.restore_user_e, self.restore_item_e = None, None\n",
    "\n",
    "        # prepare batch indices\n",
    "        user = batch[0].to(self.device).long()\n",
    "        if user.dim() == 0:\n",
    "            user = user.unsqueeze(0)\n",
    "        pos_item = batch[1].to(self.device).long()\n",
    "        if pos_item.dim() == 0:\n",
    "            pos_item = pos_item.unsqueeze(0)\n",
    "\n",
    "        # compute embeddings\n",
    "        embed_user, embed_item = self.forward()\n",
    "        embed_user = embed_user.to(self.device)\n",
    "        embed_item = embed_item.to(self.device)\n",
    "\n",
    "        # positive predictions\n",
    "        u_emb = embed_user[user]\n",
    "        p_emb = embed_item[pos_item]\n",
    "        pos_pred = (u_emb * p_emb).sum(dim=1)\n",
    "\n",
    "        # ego embeddings for regularization\n",
    "        u_ego = self.embed_user(user)\n",
    "        p_ego = self.embed_item(pos_item)\n",
    "\n",
    "        # compute loss\n",
    "        neg = batch[2].to(self.device).long()\n",
    "        neg_emb = embed_item[neg]\n",
    "        neg_pred = (u_emb * neg_emb).sum(dim=1)\n",
    "        neg_ego = self.embed_item(neg)\n",
    "        loss = self._bpr_loss(pos_pred, neg_pred)\n",
    "        loss += self.reg_1 * (u_ego.norm(p=1) + p_ego.norm(p=1) + neg_ego.norm(p=1))\n",
    "        loss += self.reg_2 * (u_ego.norm() + p_ego.norm() + neg_ego.norm())\n",
    "\n",
    "        return loss\n",
    "\n",
    "    #  Ranking \n",
    "    def rank(self, test_loader):\n",
    "        if self.restore_user_e is None or self.restore_item_e is None:\n",
    "            self.restore_user_e, self.restore_item_e = self.forward()\n",
    "\n",
    "        rec_ids = torch.tensor([], device=self.device)\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            for us in test_loader:\n",
    "                us = us.to(self.device)\n",
    "                rank_list = self.full_rank(us)\n",
    "\n",
    "                rec_ids = torch.cat((rec_ids, rank_list), 0)\n",
    "\n",
    "        return rec_ids.cpu().numpy().astype(np.int32)\n",
    "    \n",
    "    def full_rank(self, u):\n",
    "        if self.restore_user_e is None or self.restore_item_e is None:\n",
    "            self.restore_user_e, self.restore_item_e = self.forward()\n",
    "\n",
    "        # ensure CPU indices for CPU embeddings and convert to long type\n",
    "        if u.device != self.restore_user_e.device:\n",
    "            u_idx = u.to(self.restore_user_e.device).long()\n",
    "        else:\n",
    "            u_idx = u.long()\n",
    "        user_emb = self.restore_user_e[u_idx]  # (batch_size, dim)\n",
    "        items_emb = self.restore_item_e  # (num_items, dim)\n",
    "        # compute scores and top-k\n",
    "        scores = torch.matmul(user_emb, items_emb.transpose(1, 0))\n",
    "        rank = torch.argsort(scores, descending=True)[:, :self.topk]\n",
    "        # move to evaluation device\n",
    "        return rank.to(self.device)\n",
    "    \n",
    "    def predict(self, u, i):\n",
    "        if self.restore_user_e is None or self.restore_item_e is None:\n",
    "            self.restore_user_e, self.restore_item_e = self.forward()\n",
    "\n",
    "        u_embedding = self.restore_user_e[u]\n",
    "        i_embedding = self.restore_item_e[i]\n",
    "        pred = torch.matmul(u_embedding, i_embedding.t())\n",
    "\n",
    "        return pred.cpu().item()\n",
    "\n",
    "    def fit(self, train_loader, val_loader, epochs: int = 10):\n",
    "        opt = optim.Adam(self.parameters(), lr=self.lr)\n",
    "        self.to(self.device)\n",
    "\n",
    "        start = 0\n",
    "        history = {'train_loss': [], 'val_ndcg': [], 'val_recall': [], 'val_precision': [], 'val_auc': []}\n",
    "        best_ndcg = -np.inf\n",
    "        patience_counter = 0\n",
    "        if (Path(self.save_path) / 'best_model.pth').exists() and self.load:\n",
    "            print(\"Load model from checkpoint\")\n",
    "            checkpoint = torch.load(Path(self.save_path) / 'best_model.pth', map_location=self.device, weights_only=False)\n",
    "            self.load_state_dict(checkpoint['model_state_dict'])\n",
    "            opt.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "            start = checkpoint['epoch'] + 1\n",
    "            history = checkpoint['history']\n",
    "            best_ndcg = max(history['val_ndcg']) if len(history['val_ndcg']) > 0 else -np.inf   \n",
    "\n",
    "        for epoch in range(start, epochs+1):\n",
    "            self.train()\n",
    "            current_loss = 0.0\n",
    "            pbar = tqdm(train_loader)\n",
    "            pbar.set_description(f'[Epoch {epoch:03d}]')\n",
    "            for batch in pbar:\n",
    "                opt.zero_grad()\n",
    "                loss = self.calc_loss(batch)\n",
    "                if torch.isnan(loss):\n",
    "                    raise ValueError(\"NaN loss encountered\")\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "                current_loss += loss.item()\n",
    "\n",
    "            epoch_loss = current_loss / len(train_loader)\n",
    "            pbar.set_postfix(loss=epoch_loss)\n",
    "            history['train_loss'].append(epoch_loss)\n",
    "\n",
    "            preds = self.rank(val_loader)\n",
    "            ndcg = NDCG(self.val_ur, preds, self.val_u)\n",
    "            recall = Recall(self.val_ur, preds, self.val_u)\n",
    "            precision = Precision(self.val_ur, preds, self.val_u)\n",
    "            history['val_ndcg'].append(ndcg)\n",
    "            history['val_recall'].append(recall)\n",
    "            history['val_precision'].append(precision)\n",
    "            if self.true_neg:\n",
    "                if self.true_neg_dict is not None:\n",
    "                    auc = AUC_true_neg(self.val_ur, self.restore_user_e[self.val_u].detach().cpu().numpy() @ self.restore_item_e.detach().cpu().numpy().T, self.true_neg_dict, self.val_u)\n",
    "                else:\n",
    "                    auc = 0.5\n",
    "                history['val_auc'].append(auc)\n",
    "                print(f\"Training - Loss {epoch_loss:.4f} | Validation - NDCG@{self.topk}: {ndcg:.4f}, Recall@{self.topk}: {recall:.4f}, Precision@{self.topk}: {precision:.4f}, AUC@{self.topk}: {auc:.4f}\")\n",
    "            else:\n",
    "                print(f\"Training - Loss {epoch_loss:.4f} | Validation - NDCG@{self.topk}: {ndcg:.4f}, Recall@{self.topk}: {recall:.4f}, Precision@{self.topk}: {precision:.4f}\")\n",
    "            \n",
    "            # Save best model\n",
    "            state = {\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': self.state_dict(),\n",
    "                'optimizer_state_dict': opt.state_dict(),\n",
    "                'history': history\n",
    "            }\n",
    "            if ndcg > best_ndcg:\n",
    "                best_ndcg = ndcg\n",
    "                torch.save(state, Path(self.save_path) / 'best_model.pth')\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                print(f'Patience counter: {patience_counter}/5')\n",
    "                \n",
    "            torch.save(state, Path(self.save_path) / 'last_model.pth')\n",
    "            \n",
    "            # Early stopping\n",
    "            if self.early_stop and patience_counter >= 5:\n",
    "                print('Satisfy early stop mechanism')\n",
    "                break\n",
    "        return history\n",
    "    \n",
    "\n",
    "\n",
    "# ============================================= RF denoiser =============================================\n",
    "def build_behavior_features(df):\n",
    "    \"\"\"\n",
    "    df: raw_df_train (TRAIN-ONLY)\n",
    "    Required cols: user_id, item_id, click, like, share, follow, watching_times\n",
    "    \"\"\"\n",
    "    agg = df.groupby(['user_id','item_id']).agg(\n",
    "        count_click=('click','sum'),\n",
    "        count_like=('like','sum'),\n",
    "        count_share=('share','sum'),\n",
    "        count_follow=('follow','sum'),\n",
    "        avg_watch_time=('watching_times','mean')\n",
    "    ).reset_index()\n",
    "\n",
    "    return agg\n",
    "\n",
    "def normalize_video_category(x):\n",
    "    if x == 0:\n",
    "        return 0\n",
    "    if x == 1:\n",
    "        return 1\n",
    "    if isinstance(x, str):\n",
    "        x = x.strip()\n",
    "        if x == '0':\n",
    "            return 2\n",
    "        if x == '1':\n",
    "            return 3\n",
    "        return 4\n",
    "    return 4\n",
    "\n",
    "\n",
    "def build_rf_features(raw_df_train):\n",
    "    \"\"\"\n",
    "    Returns X (features), y (label), feature_names\n",
    "    \"\"\"\n",
    "\n",
    "    # -------- behavior --------\n",
    "    beh = build_behavior_features(raw_df_train)\n",
    "\n",
    "    # -------- user meta --------\n",
    "    user_meta = raw_df_train[['user_id','gender','age']].drop_duplicates()\n",
    "\n",
    "    # -------- item meta --------\n",
    "    item_meta = raw_df_train[['item_id','video_category']].drop_duplicates()\n",
    "\n",
    "    item_meta['video_category'] = (\n",
    "        item_meta['video_category']\n",
    "        .apply(normalize_video_category)\n",
    "        .astype(np.int32)\n",
    "    )\n",
    "    # -------- merge --------\n",
    "    feat = beh.merge(user_meta, on='user_id', how='left') \\\n",
    "              .merge(item_meta, on='item_id', how='left')\n",
    "\n",
    "    # -------- fillna --------\n",
    "    feat[['gender','age','video_category']] = feat[['gender','age','video_category']].fillna(0)\n",
    "\n",
    "    # -------- label --------\n",
    "    # Strong positive = like | share | follow\n",
    "    feat['label'] = ((feat['count_like'] +\n",
    "                      feat['count_share'] +\n",
    "                      feat['count_follow']) > 0).astype(int)\n",
    "\n",
    "    y = feat['label'].values\n",
    "    X = feat.drop(columns=['user_id','item_id','label'])\n",
    "\n",
    "    return feat[['user_id','item_id']], X.values, y, X.columns.tolist()\n",
    "\n",
    "#Denoise ambiguous interactions using Random Forest\n",
    "def train_rf_denoiser(raw_df_train, cf_args):\n",
    "    ui_keys, X, y, feat_names = build_rf_features(raw_df_train)\n",
    "\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=cf_args['rf_n_estimators'],\n",
    "        max_depth=cf_args['rf_max_depth'],\n",
    "        random_state=cf_args['rf_random_state'],\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    rf.fit(X, y)\n",
    "\n",
    "    probs = rf.predict_proba(X)[:,1]\n",
    "\n",
    "    res = ui_keys.copy()\n",
    "    res['prob'] = probs\n",
    "    res['label'] = y\n",
    "\n",
    "    return rf, res, feat_names\n",
    "\n",
    "def denoise_interactions(rf_res, pos_th=0.6, neg_th=0.4):\n",
    "    \"\"\"\n",
    "    rf_res: output of train_rf_denoiser\n",
    "    \"\"\"\n",
    "    pos_df = rf_res[rf_res['prob'] >= pos_th][['user_id','item_id']]\n",
    "    true_neg_df = rf_res[rf_res['prob'] <= neg_th][['user_id','item_id']]\n",
    "\n",
    "    return pos_df.drop_duplicates(), true_neg_df.drop_duplicates()\n",
    "\n",
    "def prepare_training_data(raw_df_train, train_click, cf_args):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      train_pos_df : edges for LightGCN training\n",
    "      true_neg_df  : true negatives for sampler (or None)\n",
    "    \"\"\"\n",
    "\n",
    "    if not cf_args['denoise']:\n",
    "        print(\"[INFO] Denoise OFF → use click-only training\")\n",
    "        return train_click[['user_id','item_id']], None\n",
    "\n",
    "    print(\"[INFO] Denoise ON → training RF denoiser\")\n",
    "    rf, rf_res, feat_names = train_rf_denoiser(raw_df_train, cf_args)\n",
    "\n",
    "    pos_df, true_neg_df = denoise_interactions(rf_res)\n",
    "\n",
    "    print(f\"[RF] train_click edges: {len(train_click)}\")\n",
    "    print(f\"[RF] denoised positives: {len(pos_df)}\")\n",
    "    print(f\"[RF] true negatives: {len(true_neg_df)}\")\n",
    "\n",
    "    return pos_df, true_neg_df\n",
    "\n",
    "# ============================================= Reranking =============================================\n",
    "\n",
    "def get_topN_candidates(model, users, cf_args):\n",
    "    \"\"\"\n",
    "    Returns: np.ndarray [num_users, topN]\n",
    "    \"\"\"\n",
    "    model.topk = cf_args.get('rerank_topN', 20)\n",
    "    loader = get_test_loader(Cf_valDataset(users), cf_args)\n",
    "    return model.rank(loader)\n",
    "\n",
    "def build_behavior_features_ui(raw_df_train):\n",
    "    return raw_df_train.groupby(['user_id','item_id']).agg(\n",
    "        cnt_click=('click','sum'),\n",
    "        cnt_like=('like','sum'),\n",
    "        cnt_share=('share','sum'),\n",
    "        cnt_follow=('follow','sum'),\n",
    "        avg_watch=('watching_times','mean')\n",
    "    ).reset_index()\n",
    "\n",
    "def get_user_item_meta(raw_df):\n",
    "    user_meta = raw_df[['user_id','gender','age']].drop_duplicates()\n",
    "    item_meta = raw_df[['item_id','video_category']].drop_duplicates()\n",
    "    return user_meta, item_meta\n",
    "\n",
    "def build_rerank_features(\n",
    "    candidates,\n",
    "    model,\n",
    "    users,\n",
    "    raw_df_train,\n",
    "    raw_df_all\n",
    "):\n",
    "    \"\"\"\n",
    "    candidates: [num_users, topN]\n",
    "    users: user ids aligned with candidates\n",
    "    \"\"\"\n",
    "\n",
    "    # embeddings\n",
    "    U_emb, I_emb = model.forward()\n",
    "    U_emb = U_emb.detach().cpu().numpy()\n",
    "    I_emb = I_emb.detach().cpu().numpy()\n",
    "\n",
    "    # meta & behavior\n",
    "    beh = build_behavior_features_ui(raw_df_train)\n",
    "    user_meta, item_meta = get_user_item_meta(raw_df_all)\n",
    "\n",
    "    beh = encode_ui(beh)\n",
    "    user_meta = encode_ui(user_meta)\n",
    "    item_meta = encode_ui(item_meta)\n",
    "\n",
    "    beh_dict = {(u,i): list(row)  # row already contains just the behavior features after unpacking\n",
    "                for u,i,*row in beh.itertuples(index=False)}\n",
    "\n",
    "    X = []\n",
    "    keys = []\n",
    "    \n",
    "    # Debug: print embedding dimensions\n",
    "    print(f\"DEBUG: U_emb shape: {U_emb.shape}, I_emb shape: {I_emb.shape}\")\n",
    "    print(f\"DEBUG: beh_dict has {len(beh_dict)} entries\")\n",
    "    print(f\"DEBUG: user_meta shape: {user_meta.shape}, item_meta shape: {item_meta.shape}\")\n",
    "\n",
    "    for ui, u in enumerate(tqdm(users, desc=\"building reranking feature\")):\n",
    "        for rank, i in enumerate(candidates[ui]):\n",
    "            u, i = int(u), int(i)\n",
    "\n",
    "            feat = []\n",
    "            feat_debug = {}  # Track component lengths\n",
    "\n",
    "            # embeddings - convert numpy arrays to lists of floats\n",
    "            u_emb_list = [float(x) for x in U_emb[u]]\n",
    "            i_emb_list = [float(x) for x in I_emb[i]]\n",
    "            feat.extend(u_emb_list)\n",
    "            feat.extend(i_emb_list)\n",
    "            feat_debug['u_emb'] = len(u_emb_list)\n",
    "            feat_debug['i_emb'] = len(i_emb_list)\n",
    "\n",
    "            # dot product\n",
    "            feat.append(float(np.dot(U_emb[u], I_emb[i])))\n",
    "            feat_debug['dot'] = 1\n",
    "\n",
    "            # rank position\n",
    "            feat.append(float(rank))\n",
    "            feat_debug['rank'] = 1\n",
    "\n",
    "            # behavior - ensure all are floats\n",
    "            beh_feats = beh_dict.get((u,i), [0,0,0,0,0])\n",
    "            beh_feats_list = [float(x) for x in beh_feats]\n",
    "            feat.extend(beh_feats_list)\n",
    "            feat_debug['beh'] = len(beh_feats_list)\n",
    "\n",
    "            # user meta\n",
    "            um = user_meta[user_meta['user_id']==u]\n",
    "            if len(um) > 0:\n",
    "                um_vals = um[['gender','age']].values[0]\n",
    "                feat.extend([float(um_vals[0]), float(um_vals[1])])\n",
    "                feat_debug['u_meta'] = 2\n",
    "            else:\n",
    "                feat.extend([0.0, 0.0])\n",
    "                feat_debug['u_meta'] = 2\n",
    "\n",
    "            # item meta\n",
    "            im = item_meta[item_meta['item_id']==i]\n",
    "            if len(im) > 0:\n",
    "                feat.append(float(im['video_category'].values[0]))\n",
    "                feat_debug['i_meta'] = 1\n",
    "            else:\n",
    "                feat.append(0.0)\n",
    "                feat_debug['i_meta'] = 1\n",
    "            \n",
    "            # Debug first few features\n",
    "            if len(X) < 3:\n",
    "                print(f\"DEBUG: Feature {len(X)}: u={u}, i={i}, components={feat_debug}, total_len={len(feat)}\")\n",
    "\n",
    "            X.append(feat)\n",
    "            keys.append((u,i))\n",
    "\n",
    "    # First check if all features have the same length\n",
    "    if len(X) > 0:\n",
    "        feat_lens = [len(f) for f in X]\n",
    "        unique_lens = set(feat_lens)\n",
    "        if len(unique_lens) > 1:\n",
    "            print(f\"\\n⚠ WARNING: Inconsistent feature lengths detected!\")\n",
    "            print(f\"Unique lengths: {sorted(unique_lens)}\")\n",
    "            unique_counts = dict(zip(*np.unique(feat_lens, return_counts=True)))\n",
    "            print(f\"Length distribution: {unique_counts}\")\n",
    "            \n",
    "            # Show samples of each unique length\n",
    "            for length in sorted(unique_lens)[:5]:  # Show up to 5 different lengths\n",
    "                idx = next(i for i, l in enumerate(feat_lens) if l == length)\n",
    "                u, i = keys[idx]\n",
    "                print(f\"\\nSample with length {length} (index {idx}, u={u}, i={i}):\")\n",
    "                print(f\"  Feature[:10]: {X[idx][:10]}\")\n",
    "                print(f\"  Feature[-10:]: {X[idx][-10:]}\")\n",
    "    \n",
    "    try:\n",
    "        X_arr = np.array(X, dtype=np.float32)\n",
    "    except ValueError as e:\n",
    "        print(f\"\\n✗ Error converting features to array: {e}\")\n",
    "        print(f\"Total features: {len(X)}\")\n",
    "        print(f\"Feature length stats:\")\n",
    "        print(f\"  Min: {min(feat_lens)}\")\n",
    "        print(f\"  Max: {max(feat_lens)}\")\n",
    "        print(f\"  Mode: {max(set(feat_lens), key=feat_lens.count)}\")\n",
    "        \n",
    "        # Find and show the problematic features\n",
    "        mode_len = max(set(feat_lens), key=feat_lens.count)\n",
    "        problem_indices = [i for i, l in enumerate(feat_lens) if l != mode_len]\n",
    "        print(f\"\\nFound {len(problem_indices)} features with non-standard length\")\n",
    "        print(f\"Standard length: {mode_len}, Problem indices (first 10): {problem_indices[:10]}\")\n",
    "        \n",
    "        raise\n",
    "    \n",
    "    return X_arr, keys\n",
    "\n",
    "def train_reranker_rf(\n",
    "    model,\n",
    "    train_users,\n",
    "    train_ur,\n",
    "    raw_df_train,\n",
    "    raw_df_all,\n",
    "    cf_args\n",
    "):\n",
    "    # candidates from LightGCN\n",
    "    candidates = get_topN_candidates(model, train_users, cf_args)\n",
    "\n",
    "    # build features\n",
    "    X, keys = build_rerank_features(\n",
    "        candidates,\n",
    "        model,\n",
    "        train_users,\n",
    "        raw_df_train,\n",
    "        raw_df_all\n",
    "    )\n",
    "\n",
    "    # labels: whether (u,i) is positive in train_ur\n",
    "    y = np.array([\n",
    "        1 if i in train_ur.get(u, []) else 0\n",
    "        for u,i in keys\n",
    "    ])\n",
    "\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=cf_args.get('rerank_rf_estimators', 100),\n",
    "        max_depth=cf_args.get('rerank_rf_max_depth', 10),\n",
    "        random_state=cf_args.get('rerank_rf_random_state', 42),\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    rf.fit(X, y)\n",
    "\n",
    "    return rf\n",
    "\n",
    "def rerank_candidates(\n",
    "    model,\n",
    "    rf,\n",
    "    test_users,\n",
    "    raw_df_train,\n",
    "    raw_df_all,\n",
    "    cf_args\n",
    "):\n",
    "    candidates = get_topN_candidates(model, test_users, cf_args)\n",
    "\n",
    "    X, keys = build_rerank_features(\n",
    "        candidates,\n",
    "        model,\n",
    "        test_users,\n",
    "        raw_df_train,\n",
    "        raw_df_all\n",
    "    )\n",
    "\n",
    "    scores = rf.predict_proba(X)[:,1]\n",
    "\n",
    "    reranked = []\n",
    "    idx = 0\n",
    "    topN = cf_args.get('rerank_topN', 20)\n",
    "\n",
    "    for _ in tqdm(test_users, desc=\"reranking\"):\n",
    "        s = scores[idx:idx+topN]\n",
    "        c = candidates[len(reranked)]\n",
    "        order = np.argsort(-s)\n",
    "        reranked.append(c[order])\n",
    "        idx += topN\n",
    "    \n",
    "    return np.array(reranked)\n",
    "\n",
    "\n",
    "\n",
    "# ============================================= plot =============================================\n",
    "def save_results(history, test_results, cf_args):\n",
    "    \"\"\"\n",
    "    Save training history and test results to JSON file.\n",
    "    Only saves JSON-serializable configuration parameters.\n",
    "    \"\"\"\n",
    "    exp_dir =cf_args['save_path']\n",
    "    os.makedirs(exp_dir, exist_ok=True)\n",
    "\n",
    "    # Select only serializable config fields\n",
    "    config_to_save = {\n",
    "        'exp_name': cf_args['exp_name'],\n",
    "        'embedding_dim': cf_args['embedding_dim'],\n",
    "        'lr': cf_args['lr'],\n",
    "        'num_layers': cf_args['num_layers'],\n",
    "        'epochs': cf_args['epochs'],\n",
    "        'k': cf_args['k'],\n",
    "        'reg_1': cf_args['reg_1'],\n",
    "        'reg_2': cf_args['reg_2'],\n",
    "        'train_batch_size': cf_args['train_batch_size'],\n",
    "        'val_batch_size': cf_args['val_batch_size'],\n",
    "        'test_batch_size': cf_args['test_batch_size'],\n",
    "        'sample_method': cf_args.get('sample_method', cf_args.get('sampler_method', 'uniform')),\n",
    "        'sample_ratio': cf_args['sample_ratio'],\n",
    "        'num_ng': cf_args['num_ng'],\n",
    "        'test_size': cf_args['test_size'],\n",
    "        'val_size': cf_args['val_size'],\n",
    "        'denoise': cf_args['denoise'],\n",
    "        'true_neg': cf_args['true_neg'],\n",
    "        'rerank': cf_args['rerank'],\n",
    "        'user_num': cf_args['user_num'],\n",
    "        'item_num': cf_args['item_num'],\n",
    "    }\n",
    "\n",
    "    result = {\n",
    "        'config': config_to_save,\n",
    "        'final_train_loss': float(history['train_loss'][-1]) if history['train_loss'] else None,\n",
    "        'best_val_recall': float(max(history['val_recall'])) if history['val_recall'] else None,\n",
    "        'best_val_ndcg': float(max(history['val_ndcg'])) if history['val_ndcg'] else None,\n",
    "        'test_metrics': {k: float(v) for k, v in test_results.items()}\n",
    "    }\n",
    "\n",
    "    with open(os.path.join(exp_dir, 'results.json'), 'w') as f:\n",
    "        json.dump(result, f, indent=2)\n",
    "\n",
    "    print(f\"[INFO] Results saved to {exp_dir}\")\n",
    "\n",
    "def plot_training_curves(history, cf_args):\n",
    "    os.makedirs(cf_args['plot_path'], exist_ok=True)\n",
    "    exp_dir = os.path.join(cf_args['plot_path'], cf_args['exp_name'])\n",
    "    os.makedirs(exp_dir, exist_ok=True)\n",
    "\n",
    "    epochs = range(1, len(history['train_loss']) + 1)\n",
    "\n",
    "    # ----- LOSS -----\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, history['train_loss'])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('BPR Loss')\n",
    "    plt.title('Training Loss')\n",
    "    if cf_args['plot_path']:\n",
    "        plt.savefig(os.path.join(exp_dir, 'train_loss.png'), dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "    # ----- VALIDATION METRICS -----\n",
    "    if len(history['val_recall']) > 0:\n",
    "        plt.figure()\n",
    "        plt.plot(epochs, history['val_recall'], label='Recall')\n",
    "        plt.plot(epochs, history['val_ndcg'], label='NDCG')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Score')\n",
    "        plt.title(f'Validation Metrics @K={cf_args[\"k\"]}')\n",
    "        plt.legend()\n",
    "        if cf_args['plot_path']:\n",
    "            plt.savefig(os.path.join(exp_dir, 'val_metrics.png'), dpi=300)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c023ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users=34240, Items=130637\n",
      "Method of getting user-rating pairs\n",
      "Method of getting user-rating pairs\n",
      "Method of getting user-rating pairs\n"
     ]
    }
   ],
   "source": [
    "# CF Task Pipeline\n",
    "# 1. Define CF parameters\n",
    "cf_args = {\n",
    "    'save_path': './checkpoint/',\n",
    "    'plot_path': './plots/',\n",
    "    'dataset_path': './data/data.csv',\n",
    "    'device': 'cuda',\n",
    "    'exp_name': 'LightGCN_QB_video',\n",
    "    \n",
    "    # Training\n",
    "    'train_batch_size': 2048,\n",
    "    'val_batch_size': 64,\n",
    "    'test_batch_size': 64,\n",
    "\n",
    "    # Model\n",
    "    'embedding_dim': 128,\n",
    "    'lr': 0.005,\n",
    "    'num_layers': 3,\n",
    "    'epochs': 30,\n",
    "    'k': 20,\n",
    "    'reg_1': 0.0,\n",
    "    'reg_2': 0.0,\n",
    "\n",
    "    # Negative sampling\n",
    "    'sample_method': 'hybrid',  # uniform, high-pop, low-pop, true_neg, hybrid\n",
    "    'sample_ratio': 0.3,\n",
    "    'num_ng': 4,\n",
    "\n",
    "    # Data split\n",
    "    'test_size': 0.1,\n",
    "    'val_size': 0.1111,\n",
    "\n",
    "    # RF denoise\n",
    "    'rf_n_estimators': 300,\n",
    "    'rf_max_depth': 14,\n",
    "    'rf_random_state': 42,\n",
    "\n",
    "    # rerank\n",
    "    'rerank_topN': 100,\n",
    "    'rerank_rf_estimators': 300,\n",
    "    'rerank_rf_max_depth': 14,\n",
    "\n",
    "    # hybrid\n",
    "    'early_stop': True,\n",
    "    'true_neg': True,\n",
    "    'denoise': True,\n",
    "    'rerank': True,\n",
    "    'plot': True,\n",
    "    'load': False,\n",
    "}\n",
    "\n",
    "os.makedirs(cf_args['save_path'], exist_ok=True)\n",
    "os.makedirs(cf_args['plot_path'], exist_ok=True)\n",
    "\n",
    "# 2. Load and preprocess data\n",
    "# ===== Load data =====\n",
    "raw_df = pd.read_csv(cf_args['dataset_path'])\n",
    "raw_df.fillna(0, inplace=True)\n",
    "\n",
    "# ===== Fixed-universe mapping =====\n",
    "user_ids = raw_df['user_id'].unique()\n",
    "item_ids = raw_df['item_id'].unique()\n",
    "\n",
    "user_map = {u:i for i,u in enumerate(user_ids)}\n",
    "item_map = {i:j for j,i in enumerate(item_ids)}\n",
    "\n",
    "cf_args['user_num'] = len(user_map)\n",
    "cf_args['item_num'] = len(item_map)\n",
    "def encode_ui(df):\n",
    "    df = df.copy()\n",
    "    # Đảm bảo user_id và item_id là cột, nếu đang là index thì reset về cột\n",
    "    if 'user_id' not in df.columns and getattr(df.index, 'name', None) == 'user_id':\n",
    "        df = df.reset_index()  # đưa index user_id thành cột\n",
    "    if 'item_id' not in df.columns and getattr(df.index, 'name', None) == 'item_id':\n",
    "        df = df.reset_index()  # đưa index item_id thành cột\n",
    "    # Thực hiện mapping nếu cột tồn tại\n",
    "    if 'user_id' in df.columns:\n",
    "        df['user_id'] = df['user_id'].map(user_map)\n",
    "    if 'item_id' in df.columns:\n",
    "        df['item_id'] = df['item_id'].map(item_map)\n",
    "    \n",
    "    # Remove NaN (unmapped IDs) and convert to int\n",
    "    df = df.dropna(subset=[col for col in ['user_id', 'item_id'] if col in df.columns])\n",
    "    if 'user_id' in df.columns:\n",
    "        df['user_id'] = df['user_id'].astype(int)\n",
    "    if 'item_id' in df.columns:\n",
    "        df['item_id'] = df['item_id'].astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(f\"Users={cf_args['user_num']}, Items={cf_args['item_num']}\")\n",
    "\n",
    "# 3. Split train/val/test\n",
    "# ===== Click-positive interactions =====\n",
    "click_df = (\n",
    "    raw_df[raw_df['click'] == 1][['user_id','item_id']]\n",
    "    .drop_duplicates()\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# ===== Train / Test =====\n",
    "train_idx, test_idx = split_test(click_df, cf_args['test_size'])\n",
    "\n",
    "train_click_raw_full = click_df.iloc[train_idx].reset_index(drop=True)\n",
    "test_click_raw       = click_df.iloc[test_idx].reset_index(drop=True)\n",
    "\n",
    "# ===== Train / Val (IMPORTANT: split on FULL train, then slice from FULL train) =====\n",
    "train_idx2, val_idx = split_validation(train_click_raw_full, cf_args['val_size'])\n",
    "\n",
    "train_click_raw = train_click_raw_full.iloc[train_idx2].reset_index(drop=True)\n",
    "val_click_raw   = train_click_raw_full.iloc[val_idx].reset_index(drop=True)\n",
    "\n",
    "# Encode\n",
    "train_click = encode_ui(train_click_raw)\n",
    "val_click = encode_ui(val_click_raw)\n",
    "test_click = encode_ui(test_click_raw)\n",
    "\n",
    "train_ur = get_ur(train_click)\n",
    "val_ur = get_ur(val_click)\n",
    "test_ur = get_ur(test_click)\n",
    "\n",
    "cf_args['train_ur'] = train_ur\n",
    "\n",
    "cf_args['val_ur'] = val_ur\n",
    "\n",
    "cf_args['test_ur'] = test_ur\n",
    "cf_args['test_u'] = np.array(list(test_ur.keys()))\n",
    "cf_args['val_u'] = np.array(list(val_ur.keys()))\n",
    "\n",
    "train_users_raw = set(train_click_raw_full['user_id'].values)  # raw IDs\n",
    "raw_df_train = raw_df[raw_df['user_id'].isin(train_users_raw)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26757d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Running A0_Baseline =====\n",
      "[INFO] Denoise OFF → use click-only training\n",
      "[A0_Baseline] Encoded edges: 46\n",
      "get the whole sparse interaction matrix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 000]: 100%|██████████| 2647/2647 [04:41<00:00,  9.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Loss 0.1724 | Validation - NDCG@20: 0.0469, Recall@20: 0.0945, Precision@20: 0.0141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 001]: 100%|██████████| 2647/2647 [04:36<00:00,  9.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Loss 0.0584 | Validation - NDCG@20: 0.0481, Recall@20: 0.0959, Precision@20: 0.0154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 002]: 100%|██████████| 2647/2647 [04:47<00:00,  9.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Loss 0.0298 | Validation - NDCG@20: 0.0491, Recall@20: 0.0967, Precision@20: 0.0157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 003]: 100%|██████████| 2647/2647 [04:22<00:00, 10.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Loss 0.0143 | Validation - NDCG@20: 0.0502, Recall@20: 0.1010, Precision@20: 0.0159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 004]: 100%|██████████| 2647/2647 [04:23<00:00, 10.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Loss 0.0060 | Validation - NDCG@20: 0.0463, Recall@20: 0.0976, Precision@20: 0.0154\n",
      "Patience counter: 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 005]: 100%|██████████| 2647/2647 [04:24<00:00, 10.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Loss 0.0022 | Validation - NDCG@20: 0.0476, Recall@20: 0.0993, Precision@20: 0.0155\n",
      "Patience counter: 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 006]: 100%|██████████| 2647/2647 [04:29<00:00,  9.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Loss 0.0007 | Validation - NDCG@20: 0.0474, Recall@20: 0.0990, Precision@20: 0.0155\n",
      "Patience counter: 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 007]: 100%|██████████| 2647/2647 [04:23<00:00, 10.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Loss 0.0002 | Validation - NDCG@20: 0.0456, Recall@20: 0.0972, Precision@20: 0.0152\n",
      "Patience counter: 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 008]: 100%|██████████| 2647/2647 [04:43<00:00,  9.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Loss 0.0001 | Validation - NDCG@20: 0.0468, Recall@20: 0.0986, Precision@20: 0.0155\n",
      "Patience counter: 5/5\n",
      "Satisfy early stop mechanism\n",
      "[INFO] Results saved to ./checkpoint/A0_Baseline\n",
      "\n",
      "===== Running A1_Rerank =====\n",
      "[INFO] Denoise OFF → use click-only training\n",
      "[A1_Rerank] Encoded edges: 46\n",
      "get the whole sparse interaction matrix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 000]: 100%|██████████| 2647/2647 [05:02<00:00,  8.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Loss 0.1746 | Validation - NDCG@20: 0.0449, Recall@20: 0.0921, Precision@20: 0.0134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 001]: 100%|██████████| 2647/2647 [04:56<00:00,  8.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Loss 0.0620 | Validation - NDCG@20: 0.0502, Recall@20: 0.0997, Precision@20: 0.0155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 002]: 100%|██████████| 2647/2647 [04:56<00:00,  8.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Loss 0.0310 | Validation - NDCG@20: 0.0462, Recall@20: 0.0923, Precision@20: 0.0150\n",
      "Patience counter: 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 003]: 100%|██████████| 2647/2647 [04:57<00:00,  8.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Loss 0.0145 | Validation - NDCG@20: 0.0487, Recall@20: 0.0984, Precision@20: 0.0158\n",
      "Patience counter: 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 004]: 100%|██████████| 2647/2647 [04:58<00:00,  8.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Loss 0.0059 | Validation - NDCG@20: 0.0481, Recall@20: 0.0978, Precision@20: 0.0154\n",
      "Patience counter: 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 005]: 100%|██████████| 2647/2647 [04:54<00:00,  8.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Loss 0.0021 | Validation - NDCG@20: 0.0472, Recall@20: 0.0994, Precision@20: 0.0155\n",
      "Patience counter: 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 006]: 100%|██████████| 2647/2647 [05:07<00:00,  8.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Loss 0.0007 | Validation - NDCG@20: 0.0459, Recall@20: 0.0963, Precision@20: 0.0151\n",
      "Patience counter: 5/5\n",
      "Satisfy early stop mechanism\n",
      "DEBUG: U_emb shape: (34240, 128), I_emb shape: (130637, 128)\n",
      "DEBUG: beh_dict has 2431000 entries\n",
      "DEBUG: user_meta shape: (34240, 3), item_meta shape: (169708, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "building reranking feature:   0%|          | 0/34237 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Feature 0: u=0, i=1328, components={'u_emb': 128, 'i_emb': 128, 'dot': 1, 'rank': 1, 'beh': 5, 'u_meta': 2, 'i_meta': 1}, total_len=266\n",
      "DEBUG: Feature 1: u=0, i=718, components={'u_emb': 128, 'i_emb': 128, 'dot': 1, 'rank': 1, 'beh': 5, 'u_meta': 2, 'i_meta': 1}, total_len=266\n",
      "DEBUG: Feature 2: u=0, i=172, components={'u_emb': 128, 'i_emb': 128, 'dot': 1, 'rank': 1, 'beh': 5, 'u_meta': 2, 'i_meta': 1}, total_len=266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "building reranking feature:   9%|▉         | 3249/34237 [14:17<3:45:56,  2.29it/s] "
     ]
    }
   ],
   "source": [
    "\n",
    "ablation_settings = [\n",
    "    {'name': 'A0_Baseline', 'load': True,\n",
    "     'denoise': False, 'true_neg': False,\n",
    "     'sampler_method': 'uniform', 'rerank': False,\n",
    "     'save_path': './checkpoint/A0_Baseline',},\n",
    "\n",
    "    {'name': 'A1_Rerank', 'load': True,\n",
    "     'denoise': False, 'true_neg': False,\n",
    "     'sampler_method': 'uniform', 'rerank': True,\n",
    "     'save_path': './checkpoint/A1_Rerank',},\n",
    "\n",
    "    {'name': 'A2_Denoise',\n",
    "     'denoise': True, 'true_neg': False,\n",
    "     'sampler_method': 'uniform', 'rerank': False,\n",
    "     'save_path': './checkpoint/A2_Denoise',},\n",
    "\n",
    "    {'name': 'A3_TrueNeg',\n",
    "     'denoise': True, 'true_neg': True,\n",
    "     'sampler_method': 'true_neg', 'rerank': False,\n",
    "     'save_path': './checkpoint/A3_TrueNeg',},\n",
    "\n",
    "    {'name': 'A4_HybridNeg',\n",
    "     'denoise': True, 'true_neg': True,\n",
    "     'sampler_method': 'hybrid', 'rerank': False,\n",
    "     'save_path': './checkpoint/A4_HybridNeg',},\n",
    "\n",
    "    {'name': 'A5_Full',\n",
    "     'denoise': True, 'true_neg': True,\n",
    "     'sampler_method': 'hybrid', 'rerank': True,\n",
    "     'save_path': './checkpoint/A5_Full',},\n",
    "]\n",
    "\n",
    "\n",
    "ablation_results = {}\n",
    "\n",
    "for setting in ablation_settings:\n",
    "    cf_run = cf_args.copy()\n",
    "    cf_run.update(setting)\n",
    "    cf_run['exp_name'] = setting['name']\n",
    "    cf_run['save_path'] = setting['save_path']\n",
    "    cf_run['load'] = setting.get('load', False)\n",
    "    print(f\"\\n===== Running {cf_run['exp_name']} =====\")\n",
    "\n",
    "    # ----- DATA PREP -----\n",
    "    train_pos_df, true_neg_df = prepare_training_data(\n",
    "        raw_df_train, train_click, cf_run\n",
    "    )\n",
    "    train_pos_df = encode_ui(train_pos_df)\n",
    "    if true_neg_df is not None:\n",
    "        true_neg_df = encode_ui(true_neg_df)\n",
    "\n",
    "    # Validate encoded IDs (ablation loop)\n",
    "    print(f\"[{cf_run['exp_name']}] Encoded edges: {len(train_pos_df)}\")\n",
    "    if len(train_pos_df) == 0:\n",
    "        print(f\"[ERROR] No training edges for {cf_run['exp_name']}. Skipping...\")\n",
    "        continue\n",
    "    \n",
    "    assert train_pos_df['user_id'].min() >= 0, f\"Negative user_id in {cf_run['exp_name']}\"\n",
    "    assert train_pos_df['item_id'].min() >= 0, f\"Negative item_id in {cf_run['exp_name']}\"\n",
    "    assert train_pos_df['user_id'].max() < cf_run['user_num'], f\"user_id OOB in {cf_run['exp_name']}\"\n",
    "    assert train_pos_df['item_id'].max() < cf_run['item_num'], f\"item_id OOB in {cf_run['exp_name']}\"\n",
    "\n",
    "\n",
    "    # ----- TRAIN GNN -----\n",
    "    graph_df = train_pos_df.copy()\n",
    "    graph_df['click'] = 1\n",
    "    cf_run['interaction_matrix'] = get_inter_matrix(graph_df, cf_run)\n",
    "    cf_run['true_neg_dict'] = HybridNegativeSampler._build_true_neg_dict(true_neg_df) if cf_run['true_neg'] else None\n",
    "\n",
    "    os.makedirs(cf_run['save_path'], exist_ok=True)\n",
    "\n",
    "    sampler = HybridNegativeSampler(cf_run)\n",
    "    triples = sampler.sampling(\n",
    "        train_edges_df=train_pos_df,\n",
    "        train_ur=train_ur,\n",
    "        true_neg_df=true_neg_df if cf_run['true_neg'] else None\n",
    "    )\n",
    "\n",
    "    train_ds = BasicDataset(triples)\n",
    "    train_loader = get_train_loader(train_ds, cf_run)\n",
    "\n",
    "    model = LightGCN(cf_run)\n",
    "    history = model.fit(\n",
    "        train_loader,\n",
    "        val_loader=get_val_loader(Cf_valDataset(cf_args['val_u']), cf_run),\n",
    "        epochs=cf_run['epochs']\n",
    "    )\n",
    "\n",
    "    # ----- INFERENCE -----\n",
    "    if cf_run['rerank']:\n",
    "        rf_reranker = train_reranker_rf(\n",
    "            model, list(train_ur.keys()), train_ur,\n",
    "            raw_df_train, raw_df, cf_run\n",
    "        )\n",
    "        preds = rerank_candidates(\n",
    "            model, rf_reranker,\n",
    "            cf_args['test_u'], raw_df_train, raw_df, cf_run\n",
    "        )\n",
    "    else:\n",
    "        preds = get_topN_candidates(model, cf_args['test_u'], cf_run)\n",
    "\n",
    "    # ----- METRICS -----\n",
    "    results = {\n",
    "        'Recall@20': Recall(test_ur, preds, cf_args['test_u']),\n",
    "        'NDCG@20': NDCG(test_ur, preds, cf_args['test_u']),\n",
    "        'Precision@20': Precision(test_ur, preds, cf_args['test_u']),\n",
    "    }\n",
    "\n",
    "    save_results(history, results, cf_run)\n",
    "    ablation_results[setting['name']] = results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4196ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_ablation_results(log_dir, settings):\n",
    "    rows = []\n",
    "    for s in settings:\n",
    "        path = f\"{log_dir}/{s['name']}/results.json\"\n",
    "        with open(path) as f:\n",
    "            r = json.load(f)\n",
    "        row = {'Model': s['name']}\n",
    "        row.update(r['test_metrics'])\n",
    "        rows.append(row)\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "abl_df = collect_ablation_results(cf_args['save_path'], ablation_settings)\n",
    "print(abl_df)\n",
    "\n",
    "\n",
    "Ks = [5, 10, 20, 50]\n",
    "plt.figure()\n",
    "\n",
    "for name in ['A0_Baseline', 'A5_Full']:\n",
    "    ndcgs = []\n",
    "    for k in Ks:\n",
    "        cf_args['k'] = k\n",
    "        preds = get_topN_candidates(model, cf_args['test_u'], cf_args)\n",
    "        ndcgs.append(NDCG(test_ur, preds, cf_args['test_u']))\n",
    "    plt.plot(Ks, ndcgs, label=name)\n",
    "\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('NDCG@K')\n",
    "plt.legend()\n",
    "plt.title('NDCG@K Comparison')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.bar(abl_df['Model'], abl_df['NDCG@20'])\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('NDCG@20')\n",
    "plt.title('Ablation Study on QB-video')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "def load_loss(exp_name):\n",
    "    with open(f\"{cf_args['save_path']}/{exp_name}/results.json\") as f:\n",
    "        return json.load(f)['final_train_loss']\n",
    "\n",
    "# hoặc plot từ history đã lưu\n",
    "\n",
    "\n",
    "abl_df = collect_ablation_results(cf_args['save_path'], ablation_settings)\n",
    "display(abl_df)\n",
    "\n",
    "plt.figure()\n",
    "plt.bar(abl_df['Model'], abl_df['NDCG@20'])\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('NDCG@20')\n",
    "plt.title('Ablation Study on QB-video')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
